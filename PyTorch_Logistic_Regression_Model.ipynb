{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Logistic_Regression_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaoYamado/notebooks/blob/master/PyTorch_Logistic_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM_kQHz5Fwu9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/2400/1*aqNgmfyBIStLrf9k7d9cng.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P761UJ_kZwtB",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression on PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XlRXe1DaJwY",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwmVnjLUZXpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j14DYYaMZjh-",
        "colab_type": "code",
        "outputId": "cae85132-08c8-42c9-955e-7f020966e53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x = [1, 5, 10, 10, 25, 50, 70, 75, 100]\n",
        "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "colors = np.random.rand(len(x))\n",
        "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
        "plt.ylabel('Fever')\n",
        "plt.xlabel('Temperature')\n",
        "\n",
        "plt.scatter(x, y, c=colors, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwLFZ4ZBmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lc7raO-nCP4",
        "colab_type": "text"
      },
      "source": [
        "## Логистическая регрессия in-depth\n",
        "\n",
        "Prediction probability:\n",
        "\n",
        "1. Linear regression doesn't work\n",
        "2. Instead of predicting direct values: predict probability\n",
        "![alt text](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/images/cross_entropy_final_4.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQMb1k49rOe7",
        "colab_type": "text"
      },
      "source": [
        "# Building a Logistic Regression Model with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN8cglZFrY4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Step 1: Load Dataset\n",
        "Step 2: Make Dataset iterable\n",
        "Step 3: Create Model Class\n",
        "Step 4: Instantiate Model Class\n",
        "Step 5: Instantiate Loss Class\n",
        "Step 6: Instantiate Optimizer CLass\n",
        "Step 7: Train Model\n",
        "\"\"\"\n",
        "# Step 1: Loading MNIST Train Dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXAED2Htdjl",
        "colab_type": "code",
        "outputId": "66f8e6d7-5b0d-43a2-abc5-ef64d373ba72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YawMZH1tjPZ",
        "colab_type": "code",
        "outputId": "0f79d04e-ec79-4482-bc2d-1233a7c107c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0uSOZBv7la1",
        "colab_type": "code",
        "outputId": "b7f15f3a-32f4-47cc-92d6-ab77329049e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_dataset[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2dfyegIC6eK",
        "colab_type": "code",
        "outputId": "b965624b-e298-498f-a438-66ec705f82cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# inspecting training dataset first element of tuple\n",
        "# input matrix\n",
        "train_dataset[0][0].size()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xSPCBKHDV3c",
        "colab_type": "code",
        "outputId": "15957386-91c1-4a49-8589-028c41b3d3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# inspecting training dataset second element of tuple\n",
        "\"\"\" The second element actually represetns the image's label. Meaning if second element says 5, it means the 28x28 \n",
        "    matrix of number represents a digit 5.\"\"\"\n",
        "  \n",
        "train_dataset[0][1]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l1dkqsWEPuf",
        "colab_type": "text"
      },
      "source": [
        "### Displaying MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wk_wQQjEGxx",
        "colab_type": "code",
        "outputId": "e416aa3d-8061-4dbc-c04c-7df5b2b8d9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifying shape of MNIST image\n",
        "\n",
        "\"\"\" As mentioned, a single MNIST image is of the shape 28 x 28 pixels \"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "train_dataset[0][0].numpy().shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2014UYJCE1lT",
        "colab_type": "code",
        "outputId": "6fe8fa94-6f49-428f-badb-a57c6e2414d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot image of MNIST image\n",
        "show_img = train_dataset[0][0].numpy().reshape(28, 28)\n",
        "plt.imshow(show_img, cmap='gray')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f66cad1cdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P12cNpcFLHw",
        "colab_type": "code",
        "outputId": "2e1e5ed7-37b6-4aa4-ccce-941804a18291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Second element of tuple shows label\n",
        "\n",
        "train_dataset[0][1]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgHi5XkOBvJN",
        "colab_type": "code",
        "outputId": "c215930c-e683-4a21-8923-b3327f46a029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot second image of MNIST image\n",
        "\n",
        "show_img = train_dataset[1][0].numpy().reshape(28, 28)\n",
        "plt.imshow(show_img, cmap='gray')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f66ca3822b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxt2FyiCADO",
        "colab_type": "code",
        "outputId": "da6c3130-c573-4e12-bbfd-e2f93102d494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Second element of tuple shows label\n",
        "# Label\n",
        "train_dataset[1][1]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa_2fz_2HI97",
        "colab_type": "text"
      },
      "source": [
        "### Step 1b: Loading MNIST Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M_Z1haYHFyL",
        "colab_type": "code",
        "outputId": "a2fce861-9e35-495b-f2ad-32b2be3f1b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset = dsets.MNIST(root= './data',\n",
        "             train=False,\n",
        "             transform=transforms.ToTensor())\n",
        "len(test_dataset)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-7pku0CIfjw",
        "colab_type": "code",
        "outputId": "04a231c2-8351-46cd-89a0-d8f491e9aa6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test dataset elements\n",
        "\"\"\"  \n",
        "Exactly like the training set, \n",
        "the testing set has 10k tuples containing the 28x28 matrices \n",
        "and their resplective labels \n",
        "\"\"\"\n",
        "type(test_dataset[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1fCeEaDZ-Yo",
        "colab_type": "code",
        "outputId": "1dc54d8a-2efe-464c-8be5-c80b69e0669e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Image matrix\n",
        "test_dataset[0][0].size()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFnYftLzceWa",
        "colab_type": "code",
        "outputId": "b201a1ee-9956-40e9-ac03-a88494c5736d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot image sample from test dataset\n",
        "\n",
        "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
        "plt.imshow(show_img, cmap='gray')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f66ca35ca58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCcIOJEHYgSQIO5DEvwEvYRv57rmVLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBJBJngUcw53",
        "colab_type": "code",
        "outputId": "056e4029-5e9a-40d6-c15f-f57cd3dbeedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Label\n",
        "test_dataset[0][1]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcsm0MBem7zw",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Make Dataset iterable\n",
        "\n",
        "1. Aim: make the dataset iterable\n",
        "2. totaldata: 60000\n",
        "3. mini-batch: 100:\n",
        "3. Number of examples in 1 iteration\n",
        "4. Iterations: 3000\n",
        "4. 1 iteration: one mini-batch forward & backward pass\n",
        "5. epochs:\n",
        "5. epoch: running through the whole dataset once\n",
        "5. epochs = iterations : totaldata/minibatch = 3000 : 60000/100 = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNMqnA7Gc1a6",
        "colab_type": "code",
        "outputId": "f2bc8d7b-bf0c-4f41-b604-489a87a9c2f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dawaGxbpNZw",
        "colab_type": "code",
        "outputId": "e9d3f160-1257-4493-8725-a99a7d76e9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"   \n",
        "When the model goes through the whole 60k images once, \n",
        "learning how to classify 0-9, it's consider 1 epoch.\n",
        "However, there's a concept of batch size where it means the model \n",
        "would look at 100 images before updating the model's weights, \n",
        "thereby learning. When the model updates its weights (parameters) \n",
        "after looking at all the images, this is considered 1 iteration.\n",
        "\"\"\"\n",
        "batch_size = 100\n",
        "\n",
        "# We arbitrarily set 3000 iterations here whisch means the model would update 3000 times\n",
        "n_iters = 3000\n",
        "\n",
        "# One epoch consists of 60000/100 = 600 iterations.\n",
        "# Because we would like to go through 3000 iterations,\n",
        "# this implies we would have 3000/600 = 5 epochs as each epoch has 600 iterations.\n",
        "\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "num_epochs"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeuWm8zTssMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create iterable object: Training Dataset\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObH02g_I09XW",
        "colab_type": "code",
        "outputId": "0a7fd8fb-02fa-4c29-eedf-c84e7fe76f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check iterability \n",
        "import collections\n",
        "isinstance(train_loader, collections.Iterable)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cevjgc2n2VTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Iterable object: Testig dataset\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXmKTeCy2nn6",
        "colab_type": "code",
        "outputId": "9f44941b-8095-48e4-d9a5-e19fad648367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "isinstance(test_loader, collections.Iterable)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAf5kJfb2vJi",
        "colab_type": "code",
        "outputId": "ef01bd36-07f0-4b7d-8175-3e37485561cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Iterate through dataset\n",
        "img_1 = np.ones((28, 28))\n",
        "img_2 = np.ones((28, 28))\n",
        "lst = [img_1, img_2]\n",
        "\n",
        "# Need to iterate\n",
        "# Think of numbers as the images\n",
        "for i in lst:\n",
        "  print(i.shape)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAykZcl93hpN",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlamvGoy3ZzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model class: same as linear regression!:\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegressionModel, self).__init__()\n",
        "    self.linear = nn.Linear(input_dim, output_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwEF4W1Y4P3_",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Instantiate Model Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmqwyzBD4jUr",
        "colab_type": "text"
      },
      "source": [
        "Input dimension(input_dim): Size of image = 28 x 28 (784)\n",
        "Ouput dimension(output_dim): 10 (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD9dDM1Y4OLz",
        "colab_type": "code",
        "outputId": "46f6bd81-1614-4fa2-b563-95a0e71564f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check size of dataset \n",
        "# this should be 28 x 28\n",
        "train_dataset[0][0].size() "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXGishnK5FhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate model class based on input and ou dimensions\n",
        "\n",
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "\n",
        "model = LogisticRegressionModel(input_dim, output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntb4HhFV7T5a",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Instantiate Loss Class.\n",
        "Logistic Regression: Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kNU1uc27m1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Cross Entry Loss Class\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOPOHr9N8Dmq",
        "colab_type": "text"
      },
      "source": [
        "**What happens in nn.CrossEntropyLoss()?**\n",
        "It does 2 things at the same time.\n",
        "\n",
        "\n",
        "1. Computes softmax(logistic/softmax function)\n",
        "2. Computes cross entropy\n",
        "![alt text](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/images/cross_entropy_final_4.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RmgXr6i8otB",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Instantiate Optimizer class\n",
        "\n",
        "\n",
        "*   Simlified equation\n",
        "  *  <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
        "  <semantics>\n",
        "    <mrow>\n",
        "      <mi>&#x03B8;<!-- θ --></mi>\n",
        "      <mo>=</mo>\n",
        "      <mi>&#x03B8;<!-- θ --></mi>\n",
        "      <mo>&#x2212;<!-- − --></mo>\n",
        "      <mi>&#x03B7;<!-- η --></mi>\n",
        "      <mo>&#x22C5;<!-- ⋅ --></mo>\n",
        "      <msub>\n",
        "        <mi mathvariant=\"normal\">&#x2207;<!-- ∇ --></mi>\n",
        "        <mi>&#x03B8;<!-- θ --></mi>\n",
        "      </msub>\n",
        "    </mrow>\n",
        "    <annotation encoding=\"application/x-tex\">\n",
        "  </semantics>\n",
        "</math>, where <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
        "  <semantics>\n",
        "    <mi>&#x03B8;<!-- θ --></mi>\n",
        "    <annotation encoding=\"application/x-tex\"></annotation>\n",
        "  </semantics>\n",
        "</math>: parameters (our variables), <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
        "  <semantics>\n",
        "    <mi>&#x03B7;<!-- η --></mi>\n",
        "    <annotation encoding=\"application/x-tex\"></annotation>\n",
        "  </semantics>\n",
        "</math> : learning rate (how fast we want to learn),<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
        "  <semantics>\n",
        "    <msub>\n",
        "      <mi mathvariant=\"normal\">&#x2207;<!-- ∇ --></mi>\n",
        "      <mi>&#x03B8;<!-- θ --></mi>\n",
        "    </msub>\n",
        "    <annotation encoding=\"application/x-tex\"></annotation>\n",
        "  </semantics>\n",
        "</math>: parameter's gradients\n",
        "\n",
        "*   Even simplier equation\n",
        "  *  paramaters = parameters - learning_rate * parameters_gradients\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og54fwN1-ZMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create optimizer\n",
        "learning_rate =0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHtg6ElL-ntL",
        "colab_type": "code",
        "outputId": "e20d69f4-ba75-4576-e75a-3cdbc715f692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Type of parameter object\n",
        "print(model.parameters)\n",
        "\n",
        "# Length of parameters\n",
        "print(len(list(model.parameters())))\n",
        "\n",
        "# FC 1 parameters\n",
        "print(list(model.parameters())[0].size())\n",
        "\n",
        "# FC 1 Bias parameters\n",
        "print(list(model.parameters())[1].size())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of LogisticRegressionModel(\n",
            "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
            ")>\n",
            "2\n",
            "torch.Size([10, 784])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9cB_0sRn1JM",
        "colab_type": "text"
      },
      "source": [
        "**Quick Matrix Product Review**\n",
        "\n",
        "*   Example 1: **matrix product**\n",
        "  *  A: (100, 10)\n",
        "  *  B:(10, 1)\n",
        "  *  A x B = (100, 10)x(10, 1) = (100, 1)\n",
        "*   Example 2: **matrix product**\n",
        "  *  A: (50, 5)\n",
        "  *  B: (5, 2)\n",
        "  *  A x B = (50, 2)x(5, 2) = (50, 2)\n",
        "*   Example 3: **element-wise addition**\n",
        "  *  A: (10, 1)\n",
        "  *  B: (10, 1)\n",
        "  *  A+B = (10, 1)\n",
        "\n",
        "![alt text](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/images/lr_params2.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0WfmZR8pNX2",
        "colab_type": "text"
      },
      "source": [
        "### Train Model\n",
        "\n",
        "\n",
        "\n",
        "*   Process\n",
        "  * a. Convert inputs/labels to tensors with gradients\n",
        "  * b. Clear gradient buffets\n",
        "  * c. Get output given inputs\n",
        "  * d. Get loss\n",
        "  * e. Get gradients w.r.t. parameters\n",
        "  * f. Update parameters using gradients\n",
        "     * parameters = parameters - learning_rate x parameters_gradients\n",
        "  * g. REPEAT    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5UkCAYFnvtE",
        "colab_type": "code",
        "outputId": "d2e4ce5e-2331-4843-b6b3-fe7bd32fce01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as Variable\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "        labels = labels\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images to a Torch Variable\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 1.8602105379104614. Accuracy: 68\n",
            "Iteration: 1000. Loss: 1.5906175374984741. Accuracy: 76\n",
            "Iteration: 1500. Loss: 1.293290615081787. Accuracy: 79\n",
            "Iteration: 2000. Loss: 1.0843194723129272. Accuracy: 81\n",
            "Iteration: 2500. Loss: 1.1139516830444336. Accuracy: 82\n",
            "Iteration: 3000. Loss: 1.0629172325134277. Accuracy: 82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eTTD1j6sQ93",
        "colab_type": "code",
        "outputId": "024aa3e5-6039-40c0-cc47-135e5b21dd6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# printing outputs of our model\n",
        "\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  if iter_test == 1:\n",
        "    print('OUTPUTS')\n",
        "    print(outputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUTS\n",
            "tensor([[-2.7643e-01, -1.1944e+00, -6.1484e-01,  3.5383e-02,  1.7044e-01,\n",
            "         -3.9522e-01, -1.1118e+00,  2.9647e+00, -2.4925e-01,  1.0220e+00],\n",
            "        [ 9.5764e-02, -9.5776e-02,  1.5450e+00,  1.0110e+00, -1.9993e+00,\n",
            "          7.2322e-01,  1.1475e+00, -1.9956e+00,  2.5919e-01, -1.5948e+00],\n",
            "        [-7.8561e-01,  2.3323e+00,  1.6000e-01,  4.5252e-02, -6.0604e-01,\n",
            "         -2.1371e-01, -1.2820e-01, -1.4327e-01,  8.1392e-02, -3.8280e-01],\n",
            "        [ 2.8159e+00, -2.3621e+00, -5.7895e-02, -2.9220e-01, -8.9191e-01,\n",
            "          7.0205e-01,  1.0310e+00,  2.4769e-01, -5.4130e-01, -1.2240e-01],\n",
            "        [-1.9154e-01, -2.0515e+00,  3.1549e-01, -6.6630e-01,  1.7768e+00,\n",
            "         -4.5557e-01,  3.1898e-01,  3.2401e-01, -9.6781e-02,  7.8714e-01],\n",
            "        [-1.1545e+00,  2.8872e+00,  8.5827e-02,  1.5676e-01, -6.4303e-01,\n",
            "         -2.5816e-01, -6.7467e-01, -2.8857e-02,  4.0937e-01, -2.4335e-01],\n",
            "        [-1.2616e+00, -1.1881e+00, -9.5691e-01,  2.2105e-01,  1.3838e+00,\n",
            "          5.6928e-02, -7.1266e-01,  6.0390e-01,  3.9571e-01,  8.0853e-01],\n",
            "        [-1.1593e+00, -3.0726e-01, -3.5669e-01, -3.3530e-02,  8.6288e-01,\n",
            "          3.1979e-01,  4.2184e-01,  3.0702e-01,  2.1703e-01,  1.4260e+00],\n",
            "        [ 4.0901e-01,  2.0216e-02,  6.5428e-01, -1.3831e+00,  8.1027e-01,\n",
            "          2.0775e-01,  9.3223e-01, -8.2994e-01,  1.2254e-01, -1.3121e-01],\n",
            "        [-5.9757e-01, -8.9544e-01, -1.1716e+00, -1.2216e+00,  1.0351e+00,\n",
            "         -1.0778e-01, -4.4069e-01,  1.7993e+00, -1.2598e-01,  1.8417e+00],\n",
            "        [ 3.1025e+00, -1.8691e+00,  3.6120e-01,  8.4427e-01, -1.0892e+00,\n",
            "          1.1127e+00, -4.1578e-01, -1.5377e+00,  4.6836e-01, -1.4898e+00],\n",
            "        [ 6.5091e-01, -5.0429e-01,  1.9901e-01, -1.3052e-01,  6.5556e-02,\n",
            "         -3.1266e-01,  6.1629e-01, -1.1590e+00,  1.4358e-01, -3.7847e-01],\n",
            "        [-8.2520e-01, -1.6093e+00, -6.4496e-01, -1.1297e+00,  1.5322e+00,\n",
            "         -8.6399e-02, -3.7948e-01,  1.0319e+00,  3.1520e-01,  2.1903e+00],\n",
            "        [ 2.8325e+00, -2.4600e+00, -2.6214e-01, -1.8902e-01, -4.5515e-01,\n",
            "          7.8638e-01, -3.7723e-01, -5.7157e-01,  5.4734e-01,  2.5772e-01],\n",
            "        [-1.4647e+00,  2.7242e+00, -9.5777e-02,  4.8752e-01, -1.1782e+00,\n",
            "         -1.1132e-01, -1.3765e-01, -2.1674e-01,  2.2331e-01, -2.9149e-01],\n",
            "        [ 6.5616e-01, -1.1028e+00,  1.6811e-01,  1.0943e+00, -4.4047e-01,\n",
            "          1.0218e+00, -3.8488e-01, -5.8173e-01,  2.7295e-01, -8.5538e-01],\n",
            "        [-3.1786e-01, -2.0799e+00,  6.4171e-02, -5.4572e-01,  1.4934e+00,\n",
            "         -6.1664e-01, -1.6654e-01,  1.0022e+00,  1.1428e-01,  1.5660e+00],\n",
            "        [ 3.6892e-01, -1.4377e+00, -6.0318e-01,  6.1436e-01, -1.2930e-01,\n",
            "         -1.0418e-01, -8.9992e-01,  2.7262e+00, -2.8890e-01,  6.4680e-01],\n",
            "        [-8.4450e-01, -6.9875e-01,  1.7328e-01,  1.1279e+00, -5.8485e-01,\n",
            "          2.5017e-01,  9.0323e-01, -6.9702e-01,  3.4470e-01, -5.7422e-01],\n",
            "        [-9.3145e-01, -1.5958e+00, -2.6552e-01, -1.8124e-01,  2.0740e+00,\n",
            "          1.1484e-01, -1.9111e-01,  1.2510e-01,  9.1498e-02,  1.3181e+00],\n",
            "        [-9.2574e-01, -3.9212e-01, -1.6038e+00,  8.5115e-02,  6.0586e-01,\n",
            "          1.6119e-01, -1.3330e+00,  1.6219e+00,  1.3527e-01,  1.6050e+00],\n",
            "        [-4.5581e-01, -1.3398e+00,  2.0124e-01,  2.9752e-01,  2.4596e-01,\n",
            "          5.1184e-01,  2.3305e+00, -1.2426e+00,  3.9224e-01,  1.2950e-01],\n",
            "        [-3.5368e-01,  1.3093e-01,  3.4158e-01, -5.6477e-01,  8.9459e-01,\n",
            "         -9.0812e-01,  1.0795e+00, -1.4170e-01, -1.7223e-01, -6.9061e-02],\n",
            "        [-2.1768e-02, -8.1309e-01, -5.2740e-01,  3.2976e-01,  2.6670e-02,\n",
            "          1.5450e+00,  4.3431e-01, -7.8153e-01,  8.4144e-01,  1.4231e-02],\n",
            "        [-6.7337e-01, -1.0336e+00,  1.2446e-01, -7.9283e-02,  1.3866e+00,\n",
            "         -1.1905e-01, -1.9414e-01,  2.7649e-01, -3.0067e-01,  1.1690e+00],\n",
            "        [ 4.2792e+00, -2.7832e+00,  3.3399e-01, -1.3313e+00, -3.0578e-01,\n",
            "          1.0835e+00,  1.1526e+00, -8.3210e-01, -5.3116e-02, -1.4202e+00],\n",
            "        [-7.4386e-02, -1.3548e+00, -1.7845e-01,  2.0672e-01,  4.0300e-01,\n",
            "         -1.4063e-01, -5.5562e-01,  1.8592e+00, -2.8122e-01,  1.0607e+00],\n",
            "        [-6.1871e-01, -2.2325e+00, -1.8683e-01, -7.3317e-01,  2.3272e+00,\n",
            "          1.0182e-01,  8.5574e-02, -1.5822e-01,  2.1808e-01,  1.4697e+00],\n",
            "        [ 2.5029e+00, -2.2871e+00,  1.8940e-01,  9.1004e-01, -1.2816e+00,\n",
            "          7.4001e-01, -2.9067e-01, -7.9728e-01,  7.3973e-01, -4.6564e-01],\n",
            "        [-1.1773e+00,  1.5391e+00, -2.3651e-01,  2.5276e-01, -5.8812e-01,\n",
            "          8.9429e-02,  6.2986e-02, -2.5668e-01,  4.5300e-01, -3.3054e-01],\n",
            "        [-8.3781e-01, -4.3825e-02, -1.0664e+00,  2.4631e+00, -1.1529e+00,\n",
            "          9.4621e-01, -3.9808e-01,  5.9384e-01,  1.6937e-01,  1.5735e-02],\n",
            "        [-1.0926e+00,  1.0495e+00, -7.3070e-02,  3.0899e-01, -3.8599e-01,\n",
            "          1.1979e-01, -1.7273e-01,  6.8975e-02,  2.2995e-01, -2.7028e-02],\n",
            "        [-1.0373e+00, -5.4544e-01, -6.8152e-01,  2.4707e+00, -4.1535e-01,\n",
            "          1.3213e+00, -4.9168e-01, -9.0992e-01,  6.2110e-01, -9.6267e-02],\n",
            "        [ 1.8562e+00, -1.6577e+00,  4.7926e-01, -1.7121e+00,  6.4571e-01,\n",
            "          1.2563e-01,  1.4556e+00, -6.9222e-01, -1.2066e-01, -3.2114e-01],\n",
            "        [-9.5939e-01, -3.9294e-01,  4.3977e-01, -2.7426e-01, -2.1017e-01,\n",
            "         -3.6666e-01, -1.4408e+00,  1.8175e+00,  4.4608e-01,  6.3034e-01],\n",
            "        [ 5.3849e-01, -1.2379e+00,  2.5701e+00,  1.7611e-01, -9.0476e-01,\n",
            "          6.6346e-02,  5.1708e-01, -7.5229e-01,  1.6861e-01, -1.9939e+00],\n",
            "        [-4.3450e-01, -1.5702e+00, -2.1989e-02,  1.2096e-02, -8.9411e-03,\n",
            "         -5.0186e-01, -6.5108e-01,  2.3161e+00, -1.0891e-01,  9.5885e-01],\n",
            "        [-1.3897e+00,  2.2635e+00, -2.4962e-01,  3.6115e-02, -6.9695e-01,\n",
            "          8.1161e-03, -9.0204e-02, -4.9430e-02,  4.1502e-01, -4.7846e-02],\n",
            "        [ 2.3591e-01,  4.7979e-01,  7.8548e-01,  1.2372e+00, -1.8906e+00,\n",
            "          5.0752e-01,  4.5433e-01, -1.1431e+00,  5.3188e-01, -1.2011e+00],\n",
            "        [-1.4726e+00,  3.0367e+00, -3.8302e-01,  3.8554e-01, -1.2842e+00,\n",
            "          7.5661e-02, -1.6421e-01, -6.3868e-01,  6.4619e-01, -2.4305e-01],\n",
            "        [-7.0238e-01,  1.6898e+00, -2.4268e-02,  1.7823e-01, -5.4664e-01,\n",
            "         -8.9831e-02, -1.6912e-01, -1.2203e-01,  4.0576e-02, -2.5031e-01],\n",
            "        [-6.7044e-01, -8.6620e-01, -2.1456e-01, -1.5416e-01,  2.8017e-01,\n",
            "         -1.2719e-01, -5.8064e-01,  2.3123e+00, -3.8724e-01,  1.3784e+00],\n",
            "        [-1.9114e+00, -3.8332e-01, -2.4003e-01, -4.4572e-01,  2.0579e+00,\n",
            "         -6.6988e-01, -8.6454e-01,  6.9110e-01,  4.0002e-01,  1.5981e+00],\n",
            "        [-3.0034e-01,  6.6449e-01,  1.0949e+00,  1.0986e-01, -2.1688e-01,\n",
            "         -3.1726e-01,  2.6576e-01, -1.0412e+00,  4.6153e-01, -5.0313e-01],\n",
            "        [-1.2367e+00,  1.4576e-01, -1.2379e-01,  1.5631e+00, -5.7153e-01,\n",
            "          3.6659e-01,  2.7908e-01, -1.3094e-01,  9.0909e-02, -3.5601e-01],\n",
            "        [ 1.0016e-01, -1.0316e+00, -5.2056e-01,  1.4857e+00, -4.5513e-01,\n",
            "          1.1588e+00,  1.1940e-01, -1.4326e+00,  1.0282e+00, -2.6837e-01],\n",
            "        [-1.5585e+00,  3.0909e-01,  1.5023e-01,  9.1313e-01, -2.7469e-01,\n",
            "          2.5825e-01,  1.5833e-03, -2.5207e-01,  2.7480e-01,  1.6724e-01],\n",
            "        [-7.1025e-01, -3.0537e-01,  1.5487e+00, -5.3793e-01,  4.5372e-01,\n",
            "         -7.2514e-01,  6.0962e-01, -4.5425e-01,  1.2114e-04,  7.8843e-02],\n",
            "        [-1.0610e+00, -2.6283e+00, -1.1499e+00, -8.4126e-02,  2.7547e+00,\n",
            "          3.6280e-01, -5.5586e-01,  2.5134e-01,  6.3025e-01,  2.2025e+00],\n",
            "        [-3.3114e-01, -1.9907e+00,  3.8289e-01, -5.0649e-01,  2.2278e+00,\n",
            "         -8.7761e-01,  2.2574e-01,  2.3432e-01, -2.2219e-01,  1.0461e+00],\n",
            "        [-4.9014e-02, -8.8355e-01,  2.4238e-01,  1.9766e-01, -1.9438e-01,\n",
            "          5.4203e-01,  2.2810e+00, -1.0434e+00, -6.3861e-03, -2.0021e-01],\n",
            "        [-9.2646e-02, -8.8225e-01, -1.7381e-01,  1.6327e+00, -8.4571e-01,\n",
            "          8.1989e-01, -2.4691e-01, -5.9462e-01, -4.9510e-02, -8.7091e-02],\n",
            "        [ 5.6377e-01, -1.0308e+00, -1.1763e+00, -1.0819e-01,  6.4865e-01,\n",
            "          1.4499e+00, -5.7619e-02, -1.2466e-01,  1.0686e-01,  7.0262e-01],\n",
            "        [ 2.1672e-01, -8.3837e-01, -4.4256e-01,  9.7617e-01, -1.7902e-01,\n",
            "          5.1357e-01, -3.1638e-01, -6.7199e-01,  2.8111e-01, -5.4738e-01],\n",
            "        [-1.2855e-04, -8.4902e-01,  1.1346e+00, -1.8626e-01,  5.0987e-01,\n",
            "         -7.8535e-01,  6.8087e-01, -4.8670e-01, -1.0535e-01, -6.4070e-01],\n",
            "        [ 1.5268e+00, -2.1385e+00, -4.4451e-01,  4.6324e-01, -6.8217e-01,\n",
            "          9.3732e-01,  2.6440e-01, -8.2685e-01,  1.4260e+00, -7.6024e-02],\n",
            "        [-1.0621e-01, -2.8210e+00, -4.3797e-02, -4.0507e-01,  2.6894e+00,\n",
            "          7.9747e-02,  3.0034e-01, -3.2237e-01, -1.2908e-01,  9.8653e-01],\n",
            "        [-8.4479e-01,  2.3990e+00, -3.2434e-02,  2.0235e-01, -7.7045e-01,\n",
            "         -1.4815e-01, -4.9226e-01, -1.0886e-01,  2.8770e-01, -2.5515e-01],\n",
            "        [-1.6246e-01, -1.8700e+00, -6.0037e-01, -8.7591e-01,  1.8091e+00,\n",
            "         -2.9872e-02, -1.6787e-01,  1.1262e+00, -1.8562e-01,  2.2035e+00],\n",
            "        [ 1.5820e-01,  3.6476e-01, -6.0181e-01, -4.0550e-01,  2.6561e-01,\n",
            "          4.1607e-01, -2.2652e-01,  3.1198e-01,  1.4674e-01, -2.1074e-01],\n",
            "        [-6.0664e-02, -1.6790e+00, -3.6022e-01,  9.0602e-01,  3.6345e-01,\n",
            "          1.7759e-01, -1.2795e-01,  2.0830e+00, -5.1791e-01,  7.7548e-01],\n",
            "        [ 5.9563e-02, -1.1304e+00,  1.0054e+00, -1.4300e+00, -2.0583e-01,\n",
            "          3.7440e-02,  5.3812e-01, -6.1228e-01,  1.0957e+00,  3.8453e-01],\n",
            "        [-9.1142e-01, -8.3885e-01,  1.9170e-01, -2.5518e-01,  6.9386e-01,\n",
            "          2.4328e-01,  7.8685e-02, -1.5145e-03,  4.8419e-01,  7.6297e-01],\n",
            "        [-1.0854e+00, -2.7801e-01,  1.2251e+00,  6.7258e-01, -2.0090e-01,\n",
            "         -2.4884e-01, -4.4346e-01, -7.4141e-01,  4.4920e-01,  6.3413e-02],\n",
            "        [-9.5556e-01, -7.3745e-01,  3.4182e-01, -5.1775e-01,  5.9320e-01,\n",
            "         -4.0542e-01, -5.4043e-01,  1.4945e+00,  2.1331e-01,  6.7811e-01],\n",
            "        [-1.0573e+00, -6.8088e-01, -4.3604e-01,  4.0649e-01,  6.0797e-01,\n",
            "          5.0654e-01, -2.9865e-03, -2.9375e-01,  6.1277e-01,  7.9446e-01],\n",
            "        [ 3.4504e-01, -3.0279e-01,  6.6131e-01, -1.2090e-01,  3.4606e-01,\n",
            "         -5.2443e-01,  5.2095e-01,  7.6410e-02, -4.9255e-01, -4.5463e-01],\n",
            "        [-4.1461e-01, -1.3934e+00,  4.9372e-01, -1.0254e+00,  2.1731e+00,\n",
            "         -8.2032e-01, -1.6427e-01,  3.0584e-01,  2.8546e-01,  7.1058e-01],\n",
            "        [-1.3358e+00, -4.3244e-01, -5.5749e-01,  2.6954e+00, -5.3920e-01,\n",
            "          9.9131e-01, -1.1099e+00, -8.7528e-01,  1.2421e+00, -1.8299e-02],\n",
            "        [ 2.4907e+00, -1.4804e+00,  4.2504e-01, -5.3619e-01, -1.3017e+00,\n",
            "          5.4514e-01,  2.2741e-01,  2.1147e-01, -4.0065e-01, -5.0658e-01],\n",
            "        [ 4.3716e-01, -1.3222e+00, -8.7683e-01,  2.2103e-01, -4.3227e-02,\n",
            "         -1.9450e-01, -7.4603e-01,  2.7359e+00, -3.3691e-01,  6.2635e-01],\n",
            "        [ 4.3186e+00, -2.8174e+00,  7.3147e-01,  1.5883e-01, -1.1294e+00,\n",
            "          1.0669e+00, -1.3501e-02, -1.6349e+00,  2.9066e-01, -1.5109e+00],\n",
            "        [ 1.2588e+00, -1.3571e+00,  1.6123e+00,  1.4830e+00, -1.1383e+00,\n",
            "          1.7445e-01,  5.5142e-01, -9.2583e-01,  1.0824e-01, -1.8626e+00],\n",
            "        [-1.4170e+00,  7.0157e-01,  3.6863e-01, -1.7631e-01, -8.2731e-01,\n",
            "         -3.3847e-01, -9.0288e-01,  8.2200e-01,  1.1174e+00,  5.4503e-01],\n",
            "        [-1.4912e+00,  2.3935e+00, -3.9302e-01,  1.2432e-01, -8.7639e-01,\n",
            "          6.1598e-02, -6.8855e-02, -1.3273e-01,  5.9560e-01, -1.0035e-01],\n",
            "        [-1.5467e+00,  6.9486e-01, -2.2798e-01, -4.4159e-01,  8.2692e-01,\n",
            "         -4.7350e-01, -6.5919e-01,  1.7233e+00,  2.6057e-01,  7.8742e-01],\n",
            "        [-2.4068e-01,  1.0147e-01, -3.6717e-01,  2.1607e+00, -1.0622e+00,\n",
            "          9.8206e-01, -5.3330e-01, -1.2259e+00,  5.6773e-01, -6.9685e-01],\n",
            "        [-7.5556e-01, -4.7553e-01,  7.5214e-01, -6.6360e-01, -1.8413e-01,\n",
            "         -5.5969e-01,  7.1157e-02,  1.6577e+00, -1.5348e-01,  4.4148e-01],\n",
            "        [-1.5475e+00,  1.0406e+00, -8.4438e-01, -3.3206e-02, -5.8326e-02,\n",
            "          1.5124e-01, -5.7792e-01,  2.9976e-01,  9.7792e-01,  7.0649e-01],\n",
            "        [-5.4987e-01, -8.0630e-01, -5.6572e-01, -9.2814e-01,  1.4472e-01,\n",
            "         -1.4944e-01, -1.3155e+00,  3.3685e+00,  9.3366e-02,  9.9616e-01],\n",
            "        [-4.5730e-01, -1.8310e+00, -8.5231e-01, -1.0867e-01,  1.0138e+00,\n",
            "          5.0093e-01, -2.2561e-01,  1.4885e+00, -5.6108e-01,  1.9794e+00],\n",
            "        [ 3.8732e-02, -1.8048e+00,  6.4948e-01, -3.9873e-01,  2.0137e-01,\n",
            "          9.4522e-02,  2.4925e+00, -3.3581e-01, -1.2923e-01,  1.6533e-01],\n",
            "        [-5.8175e-01, -1.3608e+00,  3.9930e+00, -2.0437e-01, -1.3714e-01,\n",
            "         -1.2937e+00,  1.0745e+00, -1.0827e+00,  5.6770e-01, -1.2586e+00],\n",
            "        [-4.2211e-01, -1.8918e+00, -5.6590e-01, -6.3614e-02,  8.1013e-01,\n",
            "          6.0983e-03, -8.3737e-01,  2.2804e+00, -3.8171e-01,  1.7342e+00],\n",
            "        [-6.9389e-01, -7.6104e-02, -5.8362e-01, -3.5880e-01,  7.3050e-01,\n",
            "          8.6744e-01, -4.4232e-01, -3.5296e-01,  1.0255e+00,  5.4400e-01],\n",
            "        [-9.9283e-01, -2.4085e+00, -9.1890e-01,  1.1492e-01,  3.0839e+00,\n",
            "          2.5611e-01, -2.1658e-01, -3.9705e-01,  4.2962e-01,  1.2785e+00],\n",
            "        [-1.6677e+00,  4.9720e-01, -4.1819e-01, -5.7910e-01, -9.9935e-02,\n",
            "         -6.6123e-01, -1.1627e+00,  3.1159e+00,  2.5963e-01,  1.2455e+00],\n",
            "        [-1.6927e-01, -1.4128e+00, -1.1530e+00,  1.8253e+00, -1.7186e-01,\n",
            "          1.0259e+00,  5.8039e-01, -4.2800e-01, -4.9377e-03, -2.9505e-03],\n",
            "        [-1.3837e-01, -1.8595e+00,  8.6299e-01, -1.3863e+00,  1.0776e+00,\n",
            "         -5.5695e-01,  2.5698e+00, -1.8916e-01, -5.1194e-01,  2.7369e-01],\n",
            "        [-1.4930e+00,  3.0067e+00,  3.5067e-01,  4.8770e-02, -7.4203e-01,\n",
            "         -2.5421e-01, -2.5929e-01, -2.9906e-01,  5.2003e-01, -4.9385e-01],\n",
            "        [ 2.7179e-01, -6.8876e-01, -2.0897e-01,  2.7829e+00, -1.1577e+00,\n",
            "          6.2236e-01, -1.1801e+00, -5.6476e-01,  8.8917e-01, -4.5985e-01],\n",
            "        [-7.7642e-01, -4.7567e-01,  5.6581e-01, -6.6149e-01,  4.6407e-01,\n",
            "         -1.9414e-01,  2.7987e+00, -1.0239e+00,  3.7191e-01,  1.0817e-01],\n",
            "        [-9.9015e-01,  2.6867e-02,  9.5731e-02, -6.7299e-01,  6.2855e-01,\n",
            "          6.7111e-02, -1.3151e-02, -2.1933e-01,  6.5823e-01,  3.0783e-01],\n",
            "        [-9.0236e-01, -5.6451e-01, -7.5819e-01,  2.6197e+00, -1.4424e+00,\n",
            "          1.0935e+00, -1.1499e+00,  5.2938e-01,  5.5892e-01,  1.9996e-01],\n",
            "        [-2.2790e+00,  1.8611e+00,  1.3079e-01,  3.1064e-01, -5.8278e-01,\n",
            "          2.0513e-01,  2.1738e-01, -5.3935e-01,  8.2576e-01, -3.8858e-02],\n",
            "        [-8.2033e-01, -3.3098e-01, -2.1674e-01, -1.3155e+00,  2.1890e+00,\n",
            "         -1.9562e-01,  4.1139e-01, -6.9722e-02,  2.2087e-02,  1.2104e+00],\n",
            "        [-1.1683e+00,  4.3810e-01, -1.3461e-01,  4.5668e-01, -2.6704e-01,\n",
            "          2.2178e-01, -1.4578e-01,  7.2510e-02,  3.7647e-01,  2.0058e-01],\n",
            "        [-1.9480e+00,  1.6213e+00, -7.6875e-01,  4.5109e-01, -4.0486e-01,\n",
            "          1.1126e-01, -1.4746e-01,  8.1841e-01,  4.0518e-01,  5.0486e-01],\n",
            "        [ 8.6705e-01, -1.0370e+00,  8.8733e-01, -9.1157e-01, -2.7179e-01,\n",
            "          6.1679e-01,  2.1293e+00, -8.5482e-01, -9.9022e-02, -6.9677e-01],\n",
            "        [-1.1149e+00, -1.7937e+00,  2.5013e-01, -2.9968e-01,  1.6220e+00,\n",
            "         -8.2043e-01, -3.0968e-01,  1.0086e+00,  1.1840e-01,  2.2901e+00]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A318W3S6teBe",
        "colab_type": "code",
        "outputId": "36dd8420-5037-45e7-c019-ed3cc60ecff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#  Printing output size\n",
        "\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  if iter_test == 1:\n",
        "    print('OUTPUTS')\n",
        "    print(outputs.size())\n",
        "    _, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUTS\n",
            "torch.Size([100, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cDeNDbUuJ3C",
        "colab_type": "code",
        "outputId": "b0ad5db4-89ca-426b-9ae5-5dc258c61fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Printing one output\n",
        "\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  if iter_test == 1:\n",
        "    print('OUTPUTS')\n",
        "    print(outputs[0, :])\n",
        "    _, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUTS\n",
            "tensor([-0.2764, -1.1944, -0.6148,  0.0354,  0.1704, -0.3952, -1.1118,  2.9647,\n",
            "        -0.2493,  1.0220], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6XlNiqbuqWH",
        "colab_type": "code",
        "outputId": "4e6ca8b0-0913-494b-827f-17d03fc40a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Printing prediction output\n",
        "\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  if iter_test == 1:\n",
        "    print('PREDICTION')\n",
        "    print(predicted.size())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muRt8p_VvQDI",
        "colab_type": "code",
        "outputId": "3d3f9c7e-4f0f-4544-c40c-48cf51c076e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# print prediction value\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  if iter_test == 1:\n",
        "    print('PREDICTION')\n",
        "    print(predicted[0])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLpgcdUw5u1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f7c13285-9d0a-48b5-e34d-53a843fdec2f"
      },
      "source": [
        "# Print prediction, label and label size\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  if iter_test == 1:\n",
        "    print('PREDICTION')\n",
        "    print(predicted[0])\n",
        "    print('LABEL SIZE')\n",
        "    print(labels.size())\n",
        "    print('LABEL FOR IMAGE')\n",
        "    print(labels[0])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "tensor(7)\n",
            "LABEL SIZE\n",
            "torch.Size([100])\n",
            "LABEL FOR IMAGE\n",
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-T2kXrDlmbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d30279d7-10ef-458d-b2b1-77508bea50df"
      },
      "source": [
        "# print second prediction and ground truth\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  if iter_test == 1:\n",
        "    print(\"PREDICTION\")\n",
        "    print(predicted[1])\n",
        "\n",
        "    print(\"LABEL SIZE\")\n",
        "    print(labels.size())\n",
        "    print(labels[1])\n",
        " "
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "tensor(2)\n",
            "LABEL SIZE\n",
            "torch.Size([100])\n",
            "tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2EQKyXZ2TvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adaa9011-d422-4ff4-d6f5-0a1a6d79c99e"
      },
      "source": [
        "# print accuracy \n",
        "correct = 0\n",
        "total = 0\n",
        "iter_test = 0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "  iter_test += 1\n",
        "  images = images.view(-1, 28*28).requires_grad_()\n",
        "  outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  #  Total number of labels\n",
        "  total += labels.size(0)\n",
        "\n",
        "  # Total correct predictions\n",
        "  correct += (predicted == labels).sum()\n",
        "\n",
        "accuracy = 100 * (correct.item() / total)\n",
        "print(accuracy)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0yckHx26LVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d7e10dd-5fe2-4f11-e3ec-ffd1d4218578"
      },
      "source": [
        "# Explanation of Python's .sum() function\n",
        "\n",
        "# Explaining .sum() python built-in function\n",
        "# correct += (predicted == labels).sum()\n",
        "import numpy as np\n",
        "a = np.ones((10))\n",
        "print(a)\n",
        "b = np.ones((10))\n",
        "print(b)\n",
        "\n",
        "print(a == b)\n",
        "print((a == b).sum())"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[ True  True  True  True  True  True  True  True  True  True]\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg45wWQO7Ljz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model = False\n",
        "if save_model is True:\n",
        "  # saves only parameters\n",
        "  torch.save(model.state_dict(), 'awesome_logistic_regression.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}